{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Do a Churn Modelling Using an Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set the working directory\n",
    "import os\n",
    "os.chdir(r'D:\\Learning\\deeplearning\\Neural_Nets')\n",
    "\n",
    "# Classification template\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "# Including all columns from 3 through 12 (Remember that the upper bound should be 13 to add 12th row)\n",
    "# We believe all these features have an impact on customer churn.\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset, we need to make sure that the data is in the best shape  for us to apply a Neural Network. Turns out our data has Categorical variables  in the form of Strings as we could see from the xls file. Hence, they need to be encoded before inputting them into a Neural Net.\n",
    "\n",
    "Our dependent variable (churn) is also categorical, but its binary and takes only 1s and 0s. So we don't need to encode it into numbers cos its already in numerical form. So, right now, we need only to encode our dependent variables that are strings and are categorical variables.\n",
    "\n",
    "We'll use the LabelEncoder and OneHotEncoder from Python Scikit library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets see what X contains before we go ahead and enode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convert X into a pandas dataframe for excel sheet like view\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets create a function out of this as it might come in handy later on.\n",
    "\n",
    "def create_dataframe(numpy_array):\n",
    "    return(pd.DataFrame(numpy_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113756</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115047</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1       2   3  4        5  6  7  8        9\n",
       "0  619   France  Female  42  2        0  1  1  1   101349\n",
       "1  608    Spain  Female  41  1  83807.9  1  0  1   112543\n",
       "2  502   France  Female  42  8   159661  3  1  0   113932\n",
       "3  699   France  Female  39  1        0  2  0  0  93826.6\n",
       "4  850    Spain  Female  43  2   125511  1  1  1  79084.1\n",
       "5  645    Spain    Male  44  8   113756  2  1  0   149757\n",
       "6  822   France    Male  50  7        0  2  1  1  10062.8\n",
       "7  376  Germany  Female  29  4   115047  4  1  0   119347\n",
       "8  501   France    Male  44  4   142051  2  0  1  74940.5\n",
       "9  684   France    Male  27  2   134604  1  1  1  71725.7"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that only the Gender and Country fields are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll define a function to take care of encoding for us. Before that, we'll import the packages.\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def categorical_encoder(data, index):\n",
    "    label_encoder = LabelEncoder()\n",
    "    data[:, index] = label_encoder.fit_transform(data[:, index])\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes in the numpy array to be processed and the index of the field to be encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try that\n",
    "# The index of the field Country is 1\n",
    "X = categorical_encoder(X,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets see what X has in store for us now.\n",
    "\n",
    "df = create_dataframe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113756</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115047</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1       2   3  4        5  6  7  8        9\n",
       "0  619  0  Female  42  2        0  1  1  1   101349\n",
       "1  608  2  Female  41  1  83807.9  1  0  1   112543\n",
       "2  502  0  Female  42  8   159661  3  1  0   113932\n",
       "3  699  0  Female  39  1        0  2  0  0  93826.6\n",
       "4  850  2  Female  43  2   125511  1  1  1  79084.1\n",
       "5  645  2    Male  44  8   113756  2  1  0   149757\n",
       "6  822  0    Male  50  7        0  2  1  1  10062.8\n",
       "7  376  1  Female  29  4   115047  4  1  0   119347\n",
       "8  501  0    Male  44  4   142051  2  0  1  74940.5\n",
       "9  684  0    Male  27  2   134604  1  1  1  71725.7"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the countries have been encoded with France as 0, Germany as 1 and Spain as 2. Wait a sec. They are not ordinal and hence there is no relational ordering between them. Even though the numbers assigned to these countries are purely random in nature, they are in no way  better or worse than the others as the numbers suggest. We need to fix this.\n",
    "\n",
    "We could create Dummy Variables to fix this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets create another function to do this.\n",
    "# Excuse me for the bad choice of names for the function. But its descriptive!! \n",
    "\n",
    "# Once again, the numpy array and the index of the field to be encoded are the inputs to this function.\n",
    "def dummy_variable_maker(data, index):\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [index])\n",
    "    data = onehotencoder.fit_transform(data).toarray()\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Female'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-227-35f9ae6401ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdummy_variable_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-226-8b7de25e5d6d>\u001b[0m in \u001b[0;36mdummy_variable_maker\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdummy_variable_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0monehotencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monehotencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\data\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1900\u001b[0m         \"\"\"\n\u001b[0;32m   1901\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[1;32m-> 1902\u001b[1;33m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[0;32m   1903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1904\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\data\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[1;34m(X, transform, selected, copy)\u001b[0m\n\u001b[0;32m   1695\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m     \"\"\"\n\u001b[1;32m-> 1697\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1699\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    380\u001b[0m                                       force_all_finite)\n\u001b[0;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Female'"
     ]
    }
   ],
   "source": [
    "X = dummy_variable_maker(X,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oops!! Looks like we can't encode Countries unless we fix Gender first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets do that.\n",
    "# Index is 2 for gender\n",
    "X = categorical_encoder(X, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = create_dataframe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113756</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115047</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2   3  4        5  6  7  8        9\n",
       "0  619  0  0  42  2        0  1  1  1   101349\n",
       "1  608  2  0  41  1  83807.9  1  0  1   112543\n",
       "2  502  0  0  42  8   159661  3  1  0   113932\n",
       "3  699  0  0  39  1        0  2  0  0  93826.6\n",
       "4  850  2  0  43  2   125511  1  1  1  79084.1\n",
       "5  645  2  1  44  8   113756  2  1  0   149757\n",
       "6  822  0  1  50  7        0  2  1  1  10062.8\n",
       "7  376  1  0  29  4   115047  4  1  0   119347\n",
       "8  501  0  1  44  4   142051  2  0  1  74940.5\n",
       "9  684  0  1  27  2   134604  1  1  1  71725.7"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Alright, now that we have fixed our gender, lets move on to Countries\n",
    "\n",
    "X = dummy_variable_maker(X,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = create_dataframe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149756.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10062.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119346.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74940.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71725.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2      3    4     5    6          7    8    9    10         11\n",
       "0  1.0  0.0  0.0  619.0  0.0  42.0  2.0       0.00  1.0  1.0  1.0  101348.88\n",
       "1  0.0  0.0  1.0  608.0  0.0  41.0  1.0   83807.86  1.0  0.0  1.0  112542.58\n",
       "2  1.0  0.0  0.0  502.0  0.0  42.0  8.0  159660.80  3.0  1.0  0.0  113931.57\n",
       "3  1.0  0.0  0.0  699.0  0.0  39.0  1.0       0.00  2.0  0.0  0.0   93826.63\n",
       "4  0.0  0.0  1.0  850.0  0.0  43.0  2.0  125510.82  1.0  1.0  1.0   79084.10\n",
       "5  0.0  0.0  1.0  645.0  1.0  44.0  8.0  113755.78  2.0  1.0  0.0  149756.71\n",
       "6  1.0  0.0  0.0  822.0  1.0  50.0  7.0       0.00  2.0  1.0  1.0   10062.80\n",
       "7  0.0  1.0  0.0  376.0  0.0  29.0  4.0  115046.74  4.0  1.0  0.0  119346.88\n",
       "8  1.0  0.0  0.0  501.0  1.0  44.0  4.0  142051.07  2.0  0.0  1.0   74940.50\n",
       "9  1.0  0.0  0.0  684.0  1.0  27.0  2.0  134603.88  1.0  1.0  1.0   71725.73"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see, we have 11 features instead of 9 before. That's because we have created dummy variables for the country variable and since there are 3 countries, 2 additional fields have been added to accomodate them. Rows countaining France will say 1.0 on those corresponding rows and the same logic applies to the other countries as well.\n",
    "\n",
    "But before we go ahead with modelling. Lets think again. We don't need 3 dummy variables for 3 countries. We need only 2 as the 3rd one will be represented by the values that aren't the other 2 dummy variables.\n",
    "\n",
    "So, let's remove one of the dummy variable field and avoid falling into the dummy variable trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove field 1\n",
    "# We'll take all columns except the first one.\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurray!! Now we are ready to split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note that cross_validation has been replaced by model_selection in the latest version\n",
    "from sklearn.model_selection import train_test_split\n",
    "def split_date(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_date(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = create_dataframe(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>117833.30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5831.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95611.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53299.96</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42855.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75075.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8651.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173952.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>71786.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67734.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85733.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134889.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>123711.73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171340.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175224.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1      2    3     4     5          6    7    8    9          10\n",
       "0  1.0  0.0  579.0  0.0  39.0   5.0  117833.30  3.0  0.0  0.0    5831.00\n",
       "1  0.0  0.0  750.0  0.0  32.0   5.0       0.00  2.0  1.0  0.0   95611.47\n",
       "2  0.0  1.0  729.0  0.0  34.0   9.0   53299.96  2.0  1.0  1.0   42855.97\n",
       "3  0.0  1.0  689.0  1.0  38.0   5.0   75075.14  1.0  1.0  1.0    8651.92\n",
       "4  0.0  0.0  605.0  1.0  52.0   7.0       0.00  2.0  1.0  1.0  173952.50\n",
       "5  0.0  0.0  667.0  0.0  37.0   9.0   71786.90  2.0  1.0  1.0   67734.79\n",
       "6  0.0  0.0  673.0  1.0  65.0   0.0       0.00  1.0  1.0  1.0   85733.33\n",
       "7  0.0  0.0  724.0  1.0  31.0   5.0       0.00  1.0  1.0  0.0  134889.95\n",
       "8  0.0  0.0  731.0  0.0  38.0  10.0  123711.73  2.0  1.0  0.0  171340.68\n",
       "9  0.0  1.0  484.0  0.0  39.0   5.0       0.00  2.0  1.0  1.0  175224.12"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Apply Feature Scaling.\n",
    "\n",
    "Feature scaling is absolutely necessarily as there is a lot of computations -- highly compute intensive calculations and a lot of parallel computing. Feature scaling eases up all these calculations. We don't need one independent variable dominating another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def feature_scaler(data):\n",
    "    sc = StandardScaler()\n",
    "    return(sc.fit_transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_scaler(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = feature_scaler(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets see if that worked.\n",
    "df = create_dataframe(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.760216</td>\n",
       "      <td>-0.574682</td>\n",
       "      <td>-0.735507</td>\n",
       "      <td>-1.087261</td>\n",
       "      <td>0.015266</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>0.673160</td>\n",
       "      <td>2.535034</td>\n",
       "      <td>-1.553624</td>\n",
       "      <td>-1.034460</td>\n",
       "      <td>-1.640810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.568112</td>\n",
       "      <td>-0.574682</td>\n",
       "      <td>1.024427</td>\n",
       "      <td>-1.087261</td>\n",
       "      <td>-0.652609</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>-1.207724</td>\n",
       "      <td>0.804242</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>-1.034460</td>\n",
       "      <td>-0.079272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.568112</td>\n",
       "      <td>1.740094</td>\n",
       "      <td>0.808295</td>\n",
       "      <td>-1.087261</td>\n",
       "      <td>-0.461788</td>\n",
       "      <td>1.393293</td>\n",
       "      <td>-0.356937</td>\n",
       "      <td>0.804242</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>0.966688</td>\n",
       "      <td>-0.996840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.568112</td>\n",
       "      <td>1.740094</td>\n",
       "      <td>0.396614</td>\n",
       "      <td>0.919743</td>\n",
       "      <td>-0.080145</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>-0.926551</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>0.966688</td>\n",
       "      <td>-1.591746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.568112</td>\n",
       "      <td>-0.574682</td>\n",
       "      <td>-0.467915</td>\n",
       "      <td>0.919743</td>\n",
       "      <td>1.255605</td>\n",
       "      <td>0.701077</td>\n",
       "      <td>-1.207724</td>\n",
       "      <td>0.804242</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>0.966688</td>\n",
       "      <td>1.283302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.568112</td>\n",
       "      <td>-0.574682</td>\n",
       "      <td>0.170190</td>\n",
       "      <td>-1.087261</td>\n",
       "      <td>-0.175556</td>\n",
       "      <td>1.393293</td>\n",
       "      <td>-0.061844</td>\n",
       "      <td>0.804242</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>0.966688</td>\n",
       "      <td>-0.564126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.568112</td>\n",
       "      <td>-0.574682</td>\n",
       "      <td>0.231942</td>\n",
       "      <td>0.919743</td>\n",
       "      <td>2.495944</td>\n",
       "      <td>-1.721681</td>\n",
       "      <td>-1.207724</td>\n",
       "      <td>-0.926551</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>0.966688</td>\n",
       "      <td>-0.251081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.568112</td>\n",
       "      <td>-0.574682</td>\n",
       "      <td>0.756835</td>\n",
       "      <td>0.919743</td>\n",
       "      <td>-0.748020</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>-1.207724</td>\n",
       "      <td>-0.926551</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>-1.034460</td>\n",
       "      <td>0.603893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.568112</td>\n",
       "      <td>-0.574682</td>\n",
       "      <td>0.828879</td>\n",
       "      <td>-1.087261</td>\n",
       "      <td>-0.080145</td>\n",
       "      <td>1.739402</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.804242</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>-1.034460</td>\n",
       "      <td>1.237875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.568112</td>\n",
       "      <td>1.740094</td>\n",
       "      <td>-1.713248</td>\n",
       "      <td>-1.087261</td>\n",
       "      <td>0.015266</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>-1.207724</td>\n",
       "      <td>0.804242</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>0.966688</td>\n",
       "      <td>1.305420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.760216 -0.574682 -0.735507 -1.087261  0.015266  0.008860  0.673160   \n",
       "1 -0.568112 -0.574682  1.024427 -1.087261 -0.652609  0.008860 -1.207724   \n",
       "2 -0.568112  1.740094  0.808295 -1.087261 -0.461788  1.393293 -0.356937   \n",
       "3 -0.568112  1.740094  0.396614  0.919743 -0.080145  0.008860 -0.009356   \n",
       "4 -0.568112 -0.574682 -0.467915  0.919743  1.255605  0.701077 -1.207724   \n",
       "5 -0.568112 -0.574682  0.170190 -1.087261 -0.175556  1.393293 -0.061844   \n",
       "6 -0.568112 -0.574682  0.231942  0.919743  2.495944 -1.721681 -1.207724   \n",
       "7 -0.568112 -0.574682  0.756835  0.919743 -0.748020  0.008860 -1.207724   \n",
       "8 -0.568112 -0.574682  0.828879 -1.087261 -0.080145  1.739402  0.766993   \n",
       "9 -0.568112  1.740094 -1.713248 -1.087261  0.015266  0.008860 -1.207724   \n",
       "\n",
       "         7         8         9         10  \n",
       "0  2.535034 -1.553624 -1.034460 -1.640810  \n",
       "1  0.804242  0.643657 -1.034460 -0.079272  \n",
       "2  0.804242  0.643657  0.966688 -0.996840  \n",
       "3 -0.926551  0.643657  0.966688 -1.591746  \n",
       "4  0.804242  0.643657  0.966688  1.283302  \n",
       "5  0.804242  0.643657  0.966688 -0.564126  \n",
       "6 -0.926551  0.643657  0.966688 -0.251081  \n",
       "7 -0.926551  0.643657 -1.034460  0.603893  \n",
       "8  0.804242  0.643657 -1.034460  1.237875  \n",
       "9  0.804242  0.643657  0.966688  1.305420  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And that finishes the Preprocessing Stage Completely!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Lets go ahead and save this preprocessing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500,)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = y_train\n",
    "temp1 = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets get to creating the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Keras uses Theano as its backend, we need to change it to TensorFlow. We are going to restart jupyter with TensorFlow as the backend for keras using the command \"set \"KERAS_BACKEND=tensorflow\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now that we have done that we need to check one more thing.\n",
    "\n",
    "keras.backend.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's great, Keras is using tf as its image_dim_ordering. Well now we could continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the even that it needs to be changed, we'll use this custom function.\n",
    "# This works only when the backend is already TensorFlow.\n",
    "def change_image_dim_ordering():\n",
    "    K = keras.backend.backend()\n",
    "    if K=='tensorflow':\n",
    "        keras.backend.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, moving on.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The sequential module is used to initialize our ANN\n",
    "from keras.models import Sequential\n",
    "# The dense module is required to build the layers of our ANN\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the ANN (.i.e define it as a sequence of layers)\n",
    "# There are 2 ways to defining an ANN. One is either by defining the sequence of layers or\n",
    "# 2 -- Defining a graph.\n",
    "\n",
    "# We are gonna use the first method. We will create an object of the Sequential class.\n",
    "# Our problem is a classification problem.\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Little Refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, \n",
    "\n",
    "Step 1 : The first step in creating an ANN is to randomly initialize the weights to small\n",
    "numbers close to 0 (not zero). This will be done by the dense function in the Dense module.\n",
    "\n",
    "Step 2 : The first observation in the dataset (the first row) is given to the the input layer,\n",
    "with each feature into one input node. In our case, we have 11 features in our feature matrix i.e the 11 independent variables. Therefore, in our input layer, we'll have 11 input nodes.\n",
    "\n",
    "Step 3 : Forward-Propogation - From left to right, the neurons are activated by the activation function in such a way that the higher the value of the activation function is for the neuron, the more the impact neuron will have in the network. There are several activation functions to choose from. But the best and the most proven one is <b>The Rectifier function</b>.\n",
    "\n",
    "<b>The Sigmoid Function</b> is the best for the output layer as we'll be able to get the probabilities for the different classes. We'll be able to see the probability that the output is 1 or 0 for each observation and even the probabilites for the new observations as we make predictions on the test set.\n",
    "\n",
    "Step 4 : Compares the predicted result to the actual result. (The churn class). This generates an error.\n",
    "\n",
    "Step 5 : Back-propogate the error from right to left. Update the weights accordingly to minimize the error. The weights that are more responsible for the generated error are targeted here. There are several ways to updating the weights. The learning rate decides by how much we update the weights.\n",
    "\n",
    "Step 6 : Repeat steps 1 to 5 either after each observation or after every batch of observations.\n",
    "\n",
    "Step 7 : When the whole training set is passed through the ANN once, that completes an epoch. Repeat epochs many more times after that.\n",
    "\n",
    "<b>Note:</b> We are going to be using Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhomi\\Anaconda2\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, kernel_initializer=\"uniform\", input_dim=11, activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "# Add the input layer and the first hidden layer.\n",
    "# The add method in our Sequential class is used to add layers to the ANN. It is only gonna\n",
    "# add the hidden layers. And thereby, by creating the first hidden layer, we are indirectly going to \n",
    "# specify the number of nodes nodes in the previous layer which is the input layer.\n",
    "\n",
    "# The first argument is -- output_dim which takes the number of nodes in the hidden layer\n",
    "# we are going to be adding.\n",
    "\n",
    "# There is no thumb rule on the number of nodes that need to added to the hidden layer. But Practioners\n",
    "# prefer to go by a number that is the average of the number of nodes in the input and output layers.\n",
    "# We could also experiment and use parameter tuning to come up with probably better numbers for specific\n",
    "# problems as well. K-fold cross-validation is one of the methods. \n",
    "\n",
    "# We have 11 input nodes and 1 for the output node (Because the output is binary). \n",
    "# So 12 in total and therefore 6 is the average.\n",
    "\n",
    "# Now that we have decided on the number of nodes in the hidden layer, the next step is to initialize\n",
    "# the weights. For out stochastic gradient descent, we have to randomly initialize the weights to \n",
    "# small numbers close to zero. And so, we can randomly initialize them with a uniform function. We \n",
    "# will use the glorot_uniform function to take care of this. For simple options, we have the \"uniform\"\n",
    "# function that will initialize the weights in a uniform distribution with values close to zero.\n",
    "\n",
    "# The third argument is the activation function. We will choose the rectifier function for the hidden \n",
    "# function. The corresponding parameter is 'relu'.\n",
    "\n",
    "# And finally, we need another mandatory parameter -- the input_dim parameter. It defines the \n",
    "# number of nodes in the input layer. It is mandatory cos we are only initializing the ANN and so we\n",
    "# have to tell the first hidden layer we are about to create, which nodes it could expect as inputs.\n",
    "# For the subsequent layers, this parameter is not needed as the next layer will already know\n",
    "# what to expect. So now, it is 11 for the input_dim.\n",
    "\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Updating the Dense Call to the Keras 2 API as per the warning:\n",
    "classifier.add(Dense(kernel_initializer=\"uniform\", units=6, activation=\"relu\", input_dim=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have added the first hidden layer, let's go ahead and add one more hidden layer. The problem we are dealing with doesn't necessarily require another one, but we will add one additional layer just to learn how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second layer\n",
    "classifier.add(Dense(kernel_initializer=\"uniform\", units=6, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x1b34f486860>,\n",
       " <keras.layers.core.Dense at 0x1b34f551860>,\n",
       " <keras.layers.core.Dense at 0x1b35215f4e0>]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we have added the hidden layers, lets add the output layer.\n",
    "# Everything is the same except the number of nodes and the activation function.\n",
    "# We are going to be using the sigmoid function.\n",
    "\n",
    "# Imagine a situation where the number of dependent variables is  more than 2 unlike the example here.\n",
    "# In that case, we need to change the units parameter and change the activation to softmax.\n",
    "# Softmax is the sigmoid function but applied to a dependent variable that has more than 2 categories.\n",
    "classifier.add(Dense(kernel_initializer=\"uniform\", units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x1b34f486860>,\n",
       " <keras.layers.core.Dense at 0x1b34f551860>,\n",
       " <keras.layers.core.Dense at 0x1b35215f4e0>,\n",
       " <keras.layers.core.Dense at 0x1b352202ba8>]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are done creating our Artificial Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lets compile our ANN by applying the Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling\n",
    "\n",
    "# It needs some parameters.\n",
    "\n",
    "# 1. Optimizer -- The algorithm we want to use to find the optimal set of weights. We have initialized\n",
    "# the weights, but we need to optimize them to find the best possible solution for the ANN.\n",
    "# \"adam\" is one of the best opitmizers - very efficient.\n",
    "\n",
    "# 2. Loss - The loss function that needs to be used within the Stochastic gradient descent algorithm.\n",
    "# That is within the adam algorithm. Stochastic gradient descent algorithm is based on a loss function.\n",
    "# (Remember that this algorithm is the best solution to find the global minimum).\n",
    "# We need to optimize it to find the optimal weights so the loss will be minimized as much as possible.\n",
    "\n",
    "# In simple linear regression, the loss function is the sum of squared errors ie. the sum of squared\n",
    "# differences between the real value and the predicted value. The problem we are dealing with here has\n",
    "# parameters that need to optimized through the stochastic gradient descent to find the optimal weights.\n",
    "\n",
    "# But in our ANN, we use the sigmoid function to find out the probability of a class occuring \n",
    "# and hence its a logistic regression model. In a logistic regression model, the loss function is not\n",
    "# SSE but is going to be a logarithmic loss function called the logarithmic loss.\n",
    "\n",
    "# The loss function we are going to use for the ANN, on which the stochastic gradient descent algorithm\n",
    "# Adam is based on, is going to be logarithmic loss. And for binary dependent variables, its called,\n",
    "# \"binary_crossentropy\" and for more than 2 categorical variables, its called \"categorical_crossentropy\"\n",
    "\n",
    "# 3. metrics -- the criterion that we choose to evaluate the model. Typically we use the accuracy\n",
    "# criterion. This will be used to improve the model. We can see the accuracy improving as we compile it.\n",
    "# The metrics parameter takes in a list of arguments. But here there is only gonna be one element\n",
    "# -- the accuracy.\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation is done. Now we could fit the ANN to the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3962 - acc: 0.8355     \n",
      "Epoch 2/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3962 - acc: 0.8352     \n",
      "Epoch 3/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3960 - acc: 0.8349     \n",
      "Epoch 4/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3965 - acc: 0.8356     \n",
      "Epoch 5/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3958 - acc: 0.8364     \n",
      "Epoch 6/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3958 - acc: 0.8357     \n",
      "Epoch 7/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3962 - acc: 0.8356     \n",
      "Epoch 8/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3955 - acc: 0.8355     \n",
      "Epoch 9/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3960 - acc: 0.8347     - ETA: 0s - loss: 0.40\n",
      "Epoch 10/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3956 - acc: 0.8347     \n",
      "Epoch 11/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3964 - acc: 0.8360     \n",
      "Epoch 12/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3954 - acc: 0.8340     \n",
      "Epoch 13/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3957 - acc: 0.8357     \n",
      "Epoch 14/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3958 - acc: 0.8351     \n",
      "Epoch 15/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3960 - acc: 0.8347     \n",
      "Epoch 16/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3958 - acc: 0.8355     \n",
      "Epoch 17/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3954 - acc: 0.8345     \n",
      "Epoch 18/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3959 - acc: 0.8357     \n",
      "Epoch 19/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3960 - acc: 0.8351     \n",
      "Epoch 20/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3960 - acc: 0.8331     \n",
      "Epoch 21/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3952 - acc: 0.8340     \n",
      "Epoch 22/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3952 - acc: 0.8359     \n",
      "Epoch 23/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3955 - acc: 0.8353     \n",
      "Epoch 24/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3962 - acc: 0.8355     \n",
      "Epoch 25/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3952 - acc: 0.8355     \n",
      "Epoch 26/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3956 - acc: 0.8343     \n",
      "Epoch 27/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3957 - acc: 0.8348     \n",
      "Epoch 28/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3954 - acc: 0.8340     \n",
      "Epoch 29/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3953 - acc: 0.8349     \n",
      "Epoch 30/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3962 - acc: 0.8360     \n",
      "Epoch 31/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3957 - acc: 0.8357     \n",
      "Epoch 32/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3955 - acc: 0.8349     \n",
      "Epoch 33/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3955 - acc: 0.8352     - ETA: 1s - loss\n",
      "Epoch 34/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3950 - acc: 0.8349     \n",
      "Epoch 35/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3950 - acc: 0.8352     \n",
      "Epoch 36/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3951 - acc: 0.8356     \n",
      "Epoch 37/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3954 - acc: 0.8356     \n",
      "Epoch 38/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3951 - acc: 0.8353     \n",
      "Epoch 39/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3953 - acc: 0.8349     \n",
      "Epoch 40/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3954 - acc: 0.8352     \n",
      "Epoch 41/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3948 - acc: 0.8335     \n",
      "Epoch 42/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3946 - acc: 0.8371     \n",
      "Epoch 43/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3952 - acc: 0.8347     \n",
      "Epoch 44/100\n",
      "7500/7500 [==============================] - 2s - loss: 0.3956 - acc: 0.8356     \n",
      "Epoch 45/100\n",
      "7500/7500 [==============================] - 2s - loss: 0.3954 - acc: 0.8353     \n",
      "Epoch 46/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3952 - acc: 0.8369     \n",
      "Epoch 47/100\n",
      "7500/7500 [==============================] - 2s - loss: 0.3953 - acc: 0.8359     \n",
      "Epoch 48/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3948 - acc: 0.8357     \n",
      "Epoch 49/100\n",
      "7500/7500 [==============================] - 2s - loss: 0.3954 - acc: 0.8353     \n",
      "Epoch 50/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3942 - acc: 0.8345     \n",
      "Epoch 51/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3951 - acc: 0.8364     \n",
      "Epoch 52/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3955 - acc: 0.8355     \n",
      "Epoch 53/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3950 - acc: 0.8361     \n",
      "Epoch 54/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3955 - acc: 0.8363     - ETA: 0s - loss: 0.3901\n",
      "Epoch 55/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3948 - acc: 0.8368     \n",
      "Epoch 56/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3948 - acc: 0.8348     \n",
      "Epoch 57/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3949 - acc: 0.8336     \n",
      "Epoch 58/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3952 - acc: 0.8363     \n",
      "Epoch 59/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3953 - acc: 0.8359     \n",
      "Epoch 60/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3945 - acc: 0.8344     \n",
      "Epoch 61/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3943 - acc: 0.8375     \n",
      "Epoch 62/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3950 - acc: 0.8371     - ETA: 0s - loss: 0.3937 \n",
      "Epoch 63/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3947 - acc: 0.8355     \n",
      "Epoch 64/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3951 - acc: 0.8353     \n",
      "Epoch 65/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3948 - acc: 0.8363     \n",
      "Epoch 66/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3951 - acc: 0.8361     \n",
      "Epoch 67/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3942 - acc: 0.8364     \n",
      "Epoch 68/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3946 - acc: 0.8349     \n",
      "Epoch 69/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3953 - acc: 0.8355     \n",
      "Epoch 70/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3952 - acc: 0.8364     \n",
      "Epoch 71/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3947 - acc: 0.8356     \n",
      "Epoch 72/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3948 - acc: 0.8352     \n",
      "Epoch 73/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3947 - acc: 0.8357     \n",
      "Epoch 74/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3946 - acc: 0.8377     - ETA: 1s - los\n",
      "Epoch 75/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3952 - acc: 0.8361     \n",
      "Epoch 76/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3944 - acc: 0.8365     \n",
      "Epoch 77/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3944 - acc: 0.8363     \n",
      "Epoch 78/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3950 - acc: 0.8361     \n",
      "Epoch 79/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3948 - acc: 0.8345     \n",
      "Epoch 80/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3946 - acc: 0.8369     \n",
      "Epoch 81/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3946 - acc: 0.8363     \n",
      "Epoch 82/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3949 - acc: 0.8355     \n",
      "Epoch 83/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3951 - acc: 0.8356     \n",
      "Epoch 84/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3947 - acc: 0.8356     \n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 1s - loss: 0.3946 - acc: 0.8367     - ETA: 0s - loss: 0\n",
      "Epoch 86/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3949 - acc: 0.8359     \n",
      "Epoch 87/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3949 - acc: 0.8352     \n",
      "Epoch 88/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3952 - acc: 0.8359     \n",
      "Epoch 89/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3954 - acc: 0.8352     \n",
      "Epoch 90/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3947 - acc: 0.8352     \n",
      "Epoch 91/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3948 - acc: 0.8364     \n",
      "Epoch 92/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3947 - acc: 0.8369     \n",
      "Epoch 93/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3943 - acc: 0.8353     \n",
      "Epoch 94/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3945 - acc: 0.8347     \n",
      "Epoch 95/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3949 - acc: 0.8343     \n",
      "Epoch 96/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3941 - acc: 0.8376     \n",
      "Epoch 97/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3946 - acc: 0.8352     \n",
      "Epoch 98/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3945 - acc: 0.8369     \n",
      "Epoch 99/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3944 - acc: 0.8359     \n",
      "Epoch 100/100\n",
      "7500/7500 [==============================] - 1s - loss: 0.3945 - acc: 0.8351     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b3536bb198>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets fit it,\n",
    "\n",
    "# We need two more arguments besides the X and y train sets. \n",
    "# 1. Again, recalling the steps involved in training the ANN with SGD, we see that we could \n",
    "# update the weights either after each observation or after a batch of observation is trained.\n",
    "\n",
    "# So the argument batch_size helps us choose this.\n",
    "\n",
    "# 2. Choose the number of epochs. \n",
    "\n",
    "# These values are completely arbitrary. Right now, we are going to choose batch size 10 and epochs 100\n",
    "classifier.fit(X_train, y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Big Shape Problem in ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does this happen?\n",
    "\n",
    "For thefinal output layer of 2 or for any number of categories the labels need to be of a categorical type where essentially it is a binary vector for each observation e.g a 3 class output vector [0,2,1,0,1,0] becomes [[1,0,0],[0,0,1],[0,1,0],[1,0,0],[0,1,0],[1,0,0]].\n",
    "\n",
    "Source -- https://stackoverflow.com/questions/31997366/python-keras-shape-mismatch-error\n",
    "\n",
    "And in our problem for the output vector [0,1,0,0,1], it becomes [[1,0],[0,1],[1,0],[1,0],[0,1]] or vice versa. We are going to make this change as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the event that it happens ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils, generic_utils\n",
    "\n",
    "y_train, y_test = [np_utils.to_categorical(x) for x in (y_train, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500,)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still we might have a problem to fix. The final y_train and y_test sets should be 1D. We'll reshape the array as per the solution suggested at https://stackoverflow.com/questions/13730468/from-nd-to-1d-arrays\n",
    "\n",
    "We'll use flatiter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lets Test our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred contains the probability that the customers leave the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1475133 ],\n",
       "       [ 0.29130149],\n",
       "       [ 0.13750894],\n",
       "       ..., \n",
       "       [ 0.23227979],\n",
       "       [ 0.21217541],\n",
       "       [ 0.08198183]], dtype=float32)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see, the first value is 14% approximately which says that this particular customer is only 14% likely to leave the bank. Down below, we see 8.1% which is again saying that the customer is almost unlikely to leave the bank. But we need to compare this to the actual observations now to see if our model is right in predicting the probabilities.\n",
    "\n",
    "Lets do it using the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of binary and continuous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-275-52969d5069a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\data\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \"\"\"\n\u001b[1;32m--> 240\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\data\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[1;32m---> 82\u001b[1;33m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't handle mix of binary and continuous"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't mix binary variables (that is our actual train_y) and the continuous variabels (that is the probabilities in pred_y). We need to convert the probabilities into a binary form too. The best way to do it is classify them based on a threshold value. We'll chose the standard .50 threshold point. Anything over this will be considered a 1 and everything else as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ..., \n",
       "       [False],\n",
       "       [False],\n",
       "       [False]], dtype=bool)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The little operation will create a Boolean array as follows:\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1942   49]\n",
      " [ 337  172]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confustion matrix says that 1942 + 172 of the 2500 data points were predicted correctly. That's an accuracy of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8456"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1942+172)/2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's an accuracy of 84%. This is a very good accuracy level considering the fact that we didn't do any parameter tuning. There is plenty of room for improvement and that should certainly increase the accuracy of our Neural Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
